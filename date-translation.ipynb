{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f690b759-faf2-4bb4-b61b-547252b54e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 18:21:38.681220: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-25 18:21:38.769705: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732569698.801869  360824 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732569698.809771  360824 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-25 18:21:38.894348: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from babel.dates import format_date\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from string_to_int import string_to_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc85356-951c-4dfd-8c4d-38885f18762c",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8020c486-a2b3-4604-9158-f08b6af955a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_vocab = pd.read_pickle('machine_vocab.pkl')\n",
    "human_vocab = pd.read_pickle('human_vocab.pkl')\n",
    "inv_machine_vocab = pd.read_pickle('inv_machine_vocab.pkl')\n",
    "dataset = pd.read_pickle('dataset.pkl')\n",
    "m = len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "577b7e96-eab2-4520-bbf4-f91bd20379e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec1c1fd-fa8b-4921-8d06-96c79429edc5",
   "metadata": {},
   "source": [
    "## String to int test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6376e69-9c07-47b1-8f2d-ab420557f0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 0, 24, 13, 34, 0, 4, 12, 12, 11, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = string_to_int(dataset[0][0], 20, human_vocab)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09727ef5-1bd4-46f3-ab3b-21ae6a0ac3be",
   "metadata": {},
   "source": [
    "## string to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9117bc5d-28ea-48e0-9ec2-ea2664eb23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, axis=1):\n",
    "    \"\"\"Softmax activation function.\n",
    "    # Arguments\n",
    "        x : Tensor.\n",
    "        axis: Integer, axis along which the softmax normalization is applied.\n",
    "    # Returns\n",
    "        Tensor, output of softmax transformation.\n",
    "    # Raises\n",
    "        ValueError: In case `dim(x) == 1`.\n",
    "    \"\"\"\n",
    "    ndim = K.ndim(x)\n",
    "    if ndim == 2:\n",
    "        return K.softmax(x)\n",
    "    elif ndim > 2:\n",
    "        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "        s = K.sum(e, axis=axis, keepdims=True)\n",
    "        return e / s\n",
    "    else:\n",
    "        raise ValueError('Cannot apply softmax to a tensor that is 1D')\n",
    "\n",
    "def preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty):   \n",
    "    X, Y = zip(*dataset)\n",
    "    \n",
    "    X = np.array([string_to_int(i, Tx, human_vocab) for i in X])\n",
    "    Y = [string_to_int(t, Ty, machine_vocab) for t in Y]\n",
    "    \n",
    "    Xoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), X)))\n",
    "    Yoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(machine_vocab)), Y)))\n",
    "\n",
    "    return X, np.array(Y), Xoh, Yoh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "398ae858-4e73-4e72-b7f2-dd032670d661",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx = 30\n",
    "Ty = 10\n",
    "X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "024c4158-3aa5-4ec5-a19c-408dedd22686",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class DatasetV2 without an implementation for abstract methods '_inputs', 'element_spec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m categorified_data \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mzip(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset(Xoh), tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset(Yoh))\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class DatasetV2 without an implementation for abstract methods '_inputs', 'element_spec'"
     ]
    }
   ],
   "source": [
    "categorified_data = tf.data.Dataset.zip(tf.data.Dataset(Xoh), tf.data.Dataset(Yoh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96012ae4-d079-4cc4-a85f-839c27a9e001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x7a15b8983900>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorified_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "766ba83c-16ae-46eb-a7cb-5d3f635a2077",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The `dataset` argument must be eithera `tf.data.Dataset`, a `torch.utils.data.Dataset`object, or a list/tuple of arrays. Received: dataset=<zip object at 0x7a15b9d20cc0> of type <class 'zip'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_set, test_set \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39msplit_dataset(\u001b[38;5;28mzip\u001b[39m(Xoh, Yoh), left_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.9\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/keras/src/utils/dataset_utils.py:55\u001b[0m, in \u001b[0;36msplit_dataset\u001b[0;34m(dataset, left_size, right_size, shuffle, seed)\u001b[0m\n\u001b[1;32m     52\u001b[0m dataset_type_spec \u001b[38;5;241m=\u001b[39m _get_type_spec(dataset)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset_type_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `dataset` argument must be either\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma `tf.data.Dataset`, a `torch.utils.data.Dataset`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject, or a list/tuple of arrays. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: dataset=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m     )\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m right_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m left_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one of the `left_size` or `right_size` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust be specified. Received: left_size=None and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright_size=None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: The `dataset` argument must be eithera `tf.data.Dataset`, a `torch.utils.data.Dataset`object, or a list/tuple of arrays. Received: dataset=<zip object at 0x7a15b9d20cc0> of type <class 'zip'>"
     ]
    }
   ],
   "source": [
    "train_set, test_set = tf.keras.utils.split_dataset(zip(Xoh, Yoh), left_size=.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b14b051-e7ce-472c-96f5-7496d82911d6",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d333134b-5fa8-4542-b550-e6d5d079a1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function keras.src.legacy.backend.softmax(x, axis=-1)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6b7d01b-3433-404d-b197-f9bee7c18c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeater = RepeatVector(Tx)\n",
    "concatenate = Concatenate(axis=-1)\n",
    "denserTanh = Dense(10, activation = \"tanh\")\n",
    "denserRelu = Dense(1, activation = \"relu\")\n",
    "activation = Activation(K.softmax, name='attention_weights')\n",
    "dot = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6302c71f-72ef-462b-bc64-89b5a9a35575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention(a, s_prev):\n",
    "    s_prev = repeater(s_prev)\n",
    "    concat = concatenate([a, s_prev])\n",
    "    e = denserTanh(concat)\n",
    "    energies = denserRelu(e)\n",
    "    alphas = activation(energies)\n",
    "    context = dot([alphas, a])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59559a24-db57-415c-a876-f37bdb844bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732569701.335858  360824 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4147 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 6GB Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "n_a = 32 # number of units for the pre-attention\n",
    "n_s = 64 # number of units for the post-attention\n",
    "\n",
    "post_activation_LSTM_cell = LSTM(n_s, return_state = True)\n",
    "output_layer = Dense(len(machine_vocab), activation=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "822b5b03-2e91-40e3-a399-8a9cce044a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Tx -- length of the input sequence\n",
    "    Ty -- length of the output sequence\n",
    "    n_a -- hidden state size of the pre-attentino Bi-LSTM\n",
    "    n_s -- hidden state size of the post-attention LSTM\n",
    "    human_vocab_size -- size of the python dictionary \"human_vocab\"\n",
    "    machine_vocab_size -- size of the python dictionary \"machine_vocab\"\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model\n",
    "    \"\"\"\n",
    "\n",
    "    X = Input(shape=(Tx, human_vocab_size))\n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')\n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    outputs = []\n",
    "    \n",
    "    a = Bidirectional(LSTM(n_a, return_sequences=True))(X)\n",
    "    \n",
    "    for t in range(Ty):\n",
    "        context = one_step_attention(a, s)\n",
    "        s, _, c = post_activation_LSTM_cell(context, initial_state=[s, c])\n",
    "        out = output_layer(s)\n",
    "        \n",
    "        outputs.append(out)\n",
    "    \n",
    "    model = Model(inputs=[X, s0, c0], outputs=outputs)  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72329e10-e58a-4510-89c9-c33256768f8e",
   "metadata": {},
   "source": [
    "## Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "babc5ec3-95ab-4d6f-add1-ab44f892efad",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.005, weight_decay=0.01)\n",
    "model = make_model(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = Ty*['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea72af4-ed9e-43fb-af71-016bcfa512da",
   "metadata": {},
   "source": [
    "## Defining the inputs\n",
    "\n",
    "Precisamos inicializar s0 e c0 com zeros, para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8698f6ff-ed90-4166-834f-60b9a887587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = np.zeros((m, n_s))\n",
    "c0 = np.zeros((m, n_s))\n",
    "outputs = list(Yoh.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2379c1-8928-4fd9-be81-0c1950862346",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7806ff88-c4ee-48ca-91cf-4c4286c2956a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ericles/miniconda3/lib/python3.12/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor', 's0', 'c0']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n",
      "I0000 00:00:1732569747.559208  360879 cuda_dnn.cc:529] Loaded cuDNN version 90501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - dense_2_accuracy: 0.6457 - dense_2_accuracy_1: 0.5903 - dense_2_accuracy_2: 0.3062 - dense_2_accuracy_3: 0.1160 - dense_2_accuracy_4: 0.6707 - dense_2_accuracy_5: 0.1904 - dense_2_accuracy_6: 0.0707 - dense_2_accuracy_7: 0.7154 - dense_2_accuracy_8: 0.1352 - dense_2_accuracy_9: 0.0666 - dense_2_loss: 2.7025 - loss: 18.6573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7a162c625e50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([Xoh, s0, c0], outputs, epochs=1, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73c36a69-b2b0-4e53-8f3c-337ae849dde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545ms/step\n",
      "source: 3 May 1979\n",
      "output: 1997-00-03 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "source: 5 April 09\n",
      "output: 2005-05-05 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "source: 21th of August 2016\n",
      "output: 2016-06-26 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "source: Tue 10 Jul 2007\n",
      "output: 2007-07-07 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "source: Saturday May 9 2018\n",
      "output: 1985-05-05 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_360824/776201906.py:10: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  output = [inv_machine_vocab[int(i)] for i in prediction]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "source: March 3 2001\n",
      "output: 2003-03-03 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "source: March 3rd 2001\n",
      "output: 2003-03-03 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "source: 1 March 2001\n",
      "output: 2000-01-03 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\n",
    "s00 = np.zeros((1, n_s))\n",
    "c00 = np.zeros((1, n_s))\n",
    "for example in EXAMPLES:\n",
    "    source = string_to_int(example, Tx, human_vocab)\n",
    "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source)))\n",
    "    source = np.expand_dims(source, axis=0)\n",
    "    prediction = model.predict([source, s00, c00])\n",
    "    prediction = np.argmax(prediction, axis = -1)\n",
    "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
    "    print(\"source:\", example)\n",
    "    print(\"output:\", ''.join(output),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a0eae27-0f30-4e87-97f6-81aac5c06cff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - dense_6_accuracy: 0.9678 - dense_6_accuracy_1: 0.9733 - dense_6_accuracy_2: 0.7353 - dense_6_accuracy_3: 0.4472 - dense_6_accuracy_4: 0.9994 - dense_6_accuracy_5: 0.9175 - dense_6_accuracy_6: 0.4575 - dense_6_accuracy_7: 0.9987 - dense_6_accuracy_8: 0.6527 - dense_6_accuracy_9: 0.4183 - dense_6_loss: 1.4640 - loss: 6.5667\n",
      "Epoch 2/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 0.9800 - dense_6_accuracy_1: 0.9828 - dense_6_accuracy_2: 0.8489 - dense_6_accuracy_3: 0.8107 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 0.9688 - dense_6_accuracy_6: 0.7988 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 0.8283 - dense_6_accuracy_9: 0.6647 - dense_6_loss: 0.9053 - loss: 3.3767\n",
      "Epoch 3/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 0.9884 - dense_6_accuracy_1: 0.9890 - dense_6_accuracy_2: 0.8909 - dense_6_accuracy_3: 0.9041 - dense_6_accuracy_4: 0.9999 - dense_6_accuracy_5: 0.9779 - dense_6_accuracy_6: 0.9161 - dense_6_accuracy_7: 0.9999 - dense_6_accuracy_8: 0.9027 - dense_6_accuracy_9: 0.8541 - dense_6_loss: 0.4333 - loss: 1.7117\n",
      "Epoch 4/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 0.9939 - dense_6_accuracy_1: 0.9950 - dense_6_accuracy_2: 0.9492 - dense_6_accuracy_3: 0.9470 - dense_6_accuracy_4: 0.9998 - dense_6_accuracy_5: 0.9798 - dense_6_accuracy_6: 0.9361 - dense_6_accuracy_7: 0.9998 - dense_6_accuracy_8: 0.9299 - dense_6_accuracy_9: 0.8923 - dense_6_loss: 0.2885 - loss: 1.1286\n",
      "Epoch 5/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - dense_6_accuracy: 0.9987 - dense_6_accuracy_1: 0.9989 - dense_6_accuracy_2: 0.9923 - dense_6_accuracy_3: 0.9827 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 0.9839 - dense_6_accuracy_6: 0.9501 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 0.9706 - dense_6_accuracy_9: 0.9372 - dense_6_loss: 0.1822 - loss: 0.6582\n",
      "Epoch 6/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 0.9998 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9975 - dense_6_accuracy_3: 0.9950 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 0.9881 - dense_6_accuracy_6: 0.9587 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 0.9853 - dense_6_accuracy_9: 0.9720 - dense_6_loss: 0.1053 - loss: 0.4277\n",
      "Epoch 7/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9993 - dense_6_accuracy_3: 0.9949 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 0.9915 - dense_6_accuracy_6: 0.9736 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 0.9932 - dense_6_accuracy_9: 0.9844 - dense_6_loss: 0.0654 - loss: 0.2846\n",
      "Epoch 8/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 0.9999 - dense_6_accuracy_2: 0.9989 - dense_6_accuracy_3: 0.9951 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 0.9920 - dense_6_accuracy_6: 0.9749 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 0.9914 - dense_6_accuracy_9: 0.9865 - dense_6_loss: 0.0530 - loss: 0.2595\n",
      "Epoch 9/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9993 - dense_6_accuracy_3: 0.9967 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 0.9965 - dense_6_accuracy_6: 0.9854 - dense_6_accuracy_7: 0.9997 - dense_6_accuracy_8: 0.9937 - dense_6_accuracy_9: 0.9920 - dense_6_loss: 0.0380 - loss: 0.1747\n",
      "Epoch 10/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9996 - dense_6_accuracy_3: 0.9954 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 0.9932 - dense_6_accuracy_6: 0.9876 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 0.9973 - dense_6_accuracy_9: 0.9936 - dense_6_loss: 0.0276 - loss: 0.1478\n",
      "Epoch 11/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9997 - dense_6_accuracy_3: 0.9965 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 0.9991 - dense_6_accuracy_6: 0.9930 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 0.9979 - dense_6_accuracy_9: 0.9952 - dense_6_loss: 0.0194 - loss: 0.0914\n",
      "Epoch 12/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9998 - dense_6_accuracy_3: 0.9973 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 0.9972 - dense_6_accuracy_6: 0.9934 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 0.9987 - dense_6_accuracy_9: 0.9968 - dense_6_loss: 0.0154 - loss: 0.0860\n",
      "Epoch 13/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9994 - dense_6_accuracy_3: 0.9959 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 0.9993 - dense_6_accuracy_6: 0.9950 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 0.9985 - dense_6_accuracy_9: 0.9974 - dense_6_loss: 0.0141 - loss: 0.0755\n",
      "Epoch 14/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9995 - dense_6_accuracy_3: 0.9955 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 0.9997 - dense_6_accuracy_6: 0.9971 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 0.9997 - dense_6_accuracy_9: 0.9987 - dense_6_loss: 0.0091 - loss: 0.0615\n",
      "Epoch 15/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9997 - dense_6_accuracy_3: 0.9967 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 0.9998 - dense_6_accuracy_6: 0.9980 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 0.9958 - dense_6_accuracy_9: 0.9964 - dense_6_loss: 0.0152 - loss: 0.0679\n",
      "Epoch 16/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9992 - dense_6_accuracy_3: 0.9944 - dense_6_accuracy_4: 0.9999 - dense_6_accuracy_5: 0.9993 - dense_6_accuracy_6: 0.9952 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 0.9988 - dense_6_accuracy_9: 0.9958 - dense_6_loss: 0.0211 - loss: 0.0834\n",
      "Epoch 17/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9997 - dense_6_accuracy_3: 0.9960 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 0.9996 - dense_6_accuracy_6: 0.9985 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 0.9973 - dense_6_accuracy_9: 0.9982 - dense_6_loss: 0.0094 - loss: 0.0549\n",
      "Epoch 18/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9995 - dense_6_accuracy_3: 0.9963 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 0.9991 - dense_6_accuracy_6: 0.9947 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 0.9987 - dense_6_accuracy_9: 0.9955 - dense_6_loss: 0.0203 - loss: 0.0842\n",
      "Epoch 19/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9998 - dense_6_accuracy_3: 0.9970 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 0.9992 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 0.9997 - dense_6_accuracy_9: 1.0000 - dense_6_loss: 0.0035 - loss: 0.0287\n",
      "Epoch 20/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 0.9999 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9997 - dense_6_accuracy_3: 0.9976 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 1.0000 - dense_6_accuracy_7: 0.9997 - dense_6_accuracy_8: 0.9999 - dense_6_accuracy_9: 1.0000 - dense_6_loss: 0.0027 - loss: 0.0244\n",
      "Epoch 21/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9996 - dense_6_accuracy_3: 0.9974 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 1.0000 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 1.0000 - dense_6_accuracy_9: 1.0000 - dense_6_loss: 0.0019 - loss: 0.0201\n",
      "Epoch 22/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9997 - dense_6_accuracy_3: 0.9987 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 1.0000 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 1.0000 - dense_6_accuracy_9: 1.0000 - dense_6_loss: 0.0018 - loss: 0.0129\n",
      "Epoch 23/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9998 - dense_6_accuracy_3: 0.9985 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 1.0000 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 1.0000 - dense_6_accuracy_9: 1.0000 - dense_6_loss: 0.0014 - loss: 0.0126\n",
      "Epoch 24/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9999 - dense_6_accuracy_3: 0.9987 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 1.0000 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 1.0000 - dense_6_accuracy_9: 1.0000 - dense_6_loss: 0.0013 - loss: 0.0129\n",
      "Epoch 25/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9998 - dense_6_accuracy_3: 0.9980 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 1.0000 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 1.0000 - dense_6_accuracy_9: 1.0000 - dense_6_loss: 0.0014 - loss: 0.0120\n",
      "Epoch 26/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9995 - dense_6_accuracy_3: 0.9987 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 1.0000 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 1.0000 - dense_6_accuracy_9: 1.0000 - dense_6_loss: 0.0011 - loss: 0.0097\n",
      "Epoch 27/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9995 - dense_6_accuracy_3: 0.9984 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 1.0000 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 1.0000 - dense_6_accuracy_9: 1.0000 - dense_6_loss: 0.0010 - loss: 0.0103\n",
      "Epoch 28/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9997 - dense_6_accuracy_3: 0.9978 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 0.9999 - dense_6_accuracy_6: 0.9992 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 0.9997 - dense_6_accuracy_9: 0.9986 - dense_6_loss: 0.0058 - loss: 0.0231\n",
      "Epoch 29/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 0.9998 - dense_6_accuracy_1: 0.9996 - dense_6_accuracy_2: 0.9968 - dense_6_accuracy_3: 0.9904 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 0.9949 - dense_6_accuracy_6: 0.9686 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 0.9888 - dense_6_accuracy_9: 0.9781 - dense_6_loss: 0.0690 - loss: 0.2865\n",
      "Epoch 30/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 0.9995 - dense_6_accuracy_1: 0.9994 - dense_6_accuracy_2: 0.9995 - dense_6_accuracy_3: 0.9961 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 0.9986 - dense_6_accuracy_6: 0.9955 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 0.9990 - dense_6_accuracy_9: 0.9975 - dense_6_loss: 0.0131 - loss: 0.0614\n",
      "Epoch 31/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9998 - dense_6_accuracy_3: 0.9977 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 0.9997 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 0.9997 - dense_6_accuracy_9: 0.9998 - dense_6_loss: 0.0042 - loss: 0.0243\n",
      "Epoch 32/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9997 - dense_6_accuracy_3: 0.9984 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 1.0000 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 1.0000 - dense_6_accuracy_9: 1.0000 - dense_6_loss: 9.9022e-04 - loss: 0.0107\n",
      "Epoch 33/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9999 - dense_6_accuracy_3: 0.9986 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 1.0000 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 1.0000 - dense_6_accuracy_9: 1.0000 - dense_6_loss: 6.6831e-04 - loss: 0.0091\n",
      "Epoch 34/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9996 - dense_6_accuracy_3: 0.9983 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 1.0000 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 1.0000 - dense_6_accuracy_9: 1.0000 - dense_6_loss: 5.7653e-04 - loss: 0.0076\n",
      "Epoch 35/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 1.0000 - dense_6_accuracy_3: 0.9984 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 1.0000 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 1.0000 - dense_6_accuracy_9: 1.0000 - dense_6_loss: 5.2427e-04 - loss: 0.0073\n",
      "Epoch 36/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9998 - dense_6_accuracy_3: 0.9989 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 1.0000 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 1.0000 - dense_6_accuracy_9: 1.0000 - dense_6_loss: 4.6367e-04 - loss: 0.0061\n",
      "Epoch 37/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9999 - dense_6_accuracy_3: 0.9978 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 1.0000 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 1.0000 - dense_6_accuracy_9: 1.0000 - dense_6_loss: 4.2708e-04 - loss: 0.0072\n",
      "Epoch 38/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9998 - dense_6_accuracy_3: 0.9982 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 1.0000 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 1.0000 - dense_6_accuracy_9: 1.0000 - dense_6_loss: 4.3229e-04 - loss: 0.0068\n",
      "Epoch 39/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9994 - dense_6_accuracy_3: 0.9985 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 1.0000 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 1.0000 - dense_6_accuracy_9: 1.0000 - dense_6_loss: 5.1859e-04 - loss: 0.0102\n",
      "Epoch 40/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 0.9999 - dense_6_accuracy_1: 0.9998 - dense_6_accuracy_2: 0.9961 - dense_6_accuracy_3: 0.9833 - dense_6_accuracy_4: 0.9994 - dense_6_accuracy_5: 0.9936 - dense_6_accuracy_6: 0.9811 - dense_6_accuracy_7: 0.9994 - dense_6_accuracy_8: 0.9829 - dense_6_accuracy_9: 0.9804 - dense_6_loss: 0.0610 - loss: 0.2697\n",
      "Epoch 41/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9995 - dense_6_accuracy_3: 0.9966 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 0.9999 - dense_6_accuracy_6: 0.9968 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 0.9982 - dense_6_accuracy_9: 0.9968 - dense_6_loss: 0.0129 - loss: 0.0641\n",
      "Epoch 42/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9995 - dense_6_accuracy_3: 0.9976 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 0.9997 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 0.9999 - dense_6_accuracy_9: 0.9994 - dense_6_loss: 0.0032 - loss: 0.0241\n",
      "Epoch 43/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9999 - dense_6_accuracy_3: 0.9970 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 0.9997 - dense_6_accuracy_6: 0.9991 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 1.0000 - dense_6_accuracy_9: 0.9998 - dense_6_loss: 0.0021 - loss: 0.0203\n",
      "Epoch 44/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 1.0000 - dense_6_accuracy_3: 0.9983 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 1.0000 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 1.0000 - dense_6_accuracy_9: 1.0000 - dense_6_loss: 6.6405e-04 - loss: 0.0090\n",
      "Epoch 45/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 1.0000 - dense_6_accuracy_3: 0.9982 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 1.0000 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 1.0000 - dense_6_accuracy_9: 1.0000 - dense_6_loss: 4.6253e-04 - loss: 0.0081\n",
      "Epoch 46/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9996 - dense_6_accuracy_3: 0.9984 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 1.0000 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 1.0000 - dense_6_accuracy_9: 1.0000 - dense_6_loss: 4.2407e-04 - loss: 0.0081\n",
      "Epoch 47/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9999 - dense_6_accuracy_3: 0.9990 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 1.0000 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 1.0000 - dense_6_accuracy_9: 1.0000 - dense_6_loss: 3.2681e-04 - loss: 0.0052\n",
      "Epoch 48/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9997 - dense_6_accuracy_3: 0.9991 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 1.0000 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 1.0000 - dense_6_accuracy_9: 1.0000 - dense_6_loss: 3.2040e-04 - loss: 0.0049\n",
      "Epoch 49/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9999 - dense_6_accuracy_3: 0.9991 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 1.0000 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 1.0000 - dense_6_accuracy_9: 1.0000 - dense_6_loss: 2.9210e-04 - loss: 0.0057\n",
      "Epoch 50/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_6_accuracy: 1.0000 - dense_6_accuracy_1: 1.0000 - dense_6_accuracy_2: 0.9999 - dense_6_accuracy_3: 0.9990 - dense_6_accuracy_4: 1.0000 - dense_6_accuracy_5: 1.0000 - dense_6_accuracy_6: 1.0000 - dense_6_accuracy_7: 1.0000 - dense_6_accuracy_8: 1.0000 - dense_6_accuracy_9: 1.0000 - dense_6_loss: 2.7874e-04 - loss: 0.0051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7386b11eabd0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([Xoh, s0, c0], outputs, epochs=50, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41687893-f134-45bd-8b25-66249f717c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "source: 3 May 1979\n",
      "output: 1979-05-03 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "source: 5 April 09\n",
      "output: 2009-04-05 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "source: 21th of August 2016\n",
      "output: 2016-08-20 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "source: Tue 10 Jul 2007\n",
      "output: 2007-06-10 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "source: Saturday May 9 2018\n",
      "output: 2018-05-09 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_352742/2649609632.py:12: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  output = [inv_machine_vocab[int(i)] for i in prediction]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "source: March 3 2001\n",
      "output: 2001-03-03 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "source: March 3rd 2001\n",
      "output: 2001-03-03 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "source: 1 March 2001\n",
      "output: 2001-03-01 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\n",
    "s00 = np.zeros((1, n_s))\n",
    "c00 = np.zeros((1, n_s))\n",
    "for example in EXAMPLES:\n",
    "    source = string_to_int(example, Tx, human_vocab)\n",
    "    #print(source)\n",
    "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source))).swapaxes(0,1)\n",
    "    source = np.swapaxes(source, 0, 1)\n",
    "    source = np.expand_dims(source, axis=0)\n",
    "    prediction = model.predict([source, s00, c00])\n",
    "    prediction = np.argmax(prediction, axis = -1)\n",
    "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
    "    print(\"source:\", example)\n",
    "    print(\"output:\", ''.join(output),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26ccd297-445c-4c79-bfea-2ece0b112d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e00136e6-dbb2-477d-8361-4e5b5903af99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 0.9674 - dense_2_accuracy_1: 0.9664 - dense_2_accuracy_2: 0.7754 - dense_2_accuracy_3: 0.4914 - dense_2_accuracy_4: 0.9996 - dense_2_accuracy_5: 0.8961 - dense_2_accuracy_6: 0.4917 - dense_2_accuracy_7: 0.9992 - dense_2_accuracy_8: 0.6140 - dense_2_accuracy_9: 0.4015 - dense_2_loss: 1.5419 - loss: 6.4895\n",
      "Epoch 2/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 0.9785 - dense_2_accuracy_1: 0.9788 - dense_2_accuracy_2: 0.8321 - dense_2_accuracy_3: 0.8277 - dense_2_accuracy_4: 0.9999 - dense_2_accuracy_5: 0.9643 - dense_2_accuracy_6: 0.7764 - dense_2_accuracy_7: 0.9997 - dense_2_accuracy_8: 0.8185 - dense_2_accuracy_9: 0.6702 - dense_2_loss: 0.9032 - loss: 3.3288\n",
      "Epoch 3/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 0.9820 - dense_2_accuracy_1: 0.9821 - dense_2_accuracy_2: 0.8693 - dense_2_accuracy_3: 0.9247 - dense_2_accuracy_4: 0.9998 - dense_2_accuracy_5: 0.9799 - dense_2_accuracy_6: 0.9058 - dense_2_accuracy_7: 0.9998 - dense_2_accuracy_8: 0.9184 - dense_2_accuracy_9: 0.8527 - dense_2_loss: 0.4338 - loss: 1.7847\n",
      "Epoch 4/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - dense_2_accuracy: 0.9893 - dense_2_accuracy_1: 0.9884 - dense_2_accuracy_2: 0.9189 - dense_2_accuracy_3: 0.9587 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9803 - dense_2_accuracy_6: 0.9283 - dense_2_accuracy_7: 0.9999 - dense_2_accuracy_8: 0.9440 - dense_2_accuracy_9: 0.8997 - dense_2_loss: 0.2778 - loss: 1.1913\n",
      "Epoch 5/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 0.9966 - dense_2_accuracy_1: 0.9957 - dense_2_accuracy_2: 0.9887 - dense_2_accuracy_3: 0.9901 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9859 - dense_2_accuracy_6: 0.9435 - dense_2_accuracy_7: 0.9997 - dense_2_accuracy_8: 0.9660 - dense_2_accuracy_9: 0.9331 - dense_2_loss: 0.1984 - loss: 0.7192\n",
      "Epoch 6/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 0.9995 - dense_2_accuracy_1: 0.9988 - dense_2_accuracy_2: 0.9983 - dense_2_accuracy_3: 0.9953 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9879 - dense_2_accuracy_6: 0.9564 - dense_2_accuracy_7: 0.9996 - dense_2_accuracy_8: 0.9771 - dense_2_accuracy_9: 0.9555 - dense_2_loss: 0.1431 - loss: 0.4917\n",
      "Epoch 7/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 0.9998 - dense_2_accuracy_1: 0.9999 - dense_2_accuracy_2: 0.9986 - dense_2_accuracy_3: 0.9969 - dense_2_accuracy_4: 0.9999 - dense_2_accuracy_5: 0.9898 - dense_2_accuracy_6: 0.9572 - dense_2_accuracy_7: 0.9999 - dense_2_accuracy_8: 0.9826 - dense_2_accuracy_9: 0.9754 - dense_2_loss: 0.0908 - loss: 0.3656\n",
      "Epoch 8/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9995 - dense_2_accuracy_3: 0.9968 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9908 - dense_2_accuracy_6: 0.9701 - dense_2_accuracy_7: 0.9999 - dense_2_accuracy_8: 0.9889 - dense_2_accuracy_9: 0.9833 - dense_2_loss: 0.0637 - loss: 0.2757\n",
      "Epoch 9/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - dense_2_accuracy: 0.9995 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9995 - dense_2_accuracy_3: 0.9964 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9930 - dense_2_accuracy_6: 0.9784 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 0.9928 - dense_2_accuracy_9: 0.9880 - dense_2_loss: 0.0466 - loss: 0.2046\n",
      "Epoch 10/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9997 - dense_2_accuracy_3: 0.9958 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9942 - dense_2_accuracy_6: 0.9854 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 0.9950 - dense_2_accuracy_9: 0.9915 - dense_2_loss: 0.0315 - loss: 0.1495\n",
      "Epoch 11/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9998 - dense_2_accuracy_3: 0.9973 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9964 - dense_2_accuracy_6: 0.9877 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 0.9940 - dense_2_accuracy_9: 0.9912 - dense_2_loss: 0.0327 - loss: 0.1369\n",
      "Epoch 12/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9997 - dense_2_accuracy_3: 0.9965 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9952 - dense_2_accuracy_6: 0.9901 - dense_2_accuracy_7: 0.9999 - dense_2_accuracy_8: 0.9977 - dense_2_accuracy_9: 0.9956 - dense_2_loss: 0.0218 - loss: 0.1166\n",
      "Epoch 13/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9990 - dense_2_accuracy_3: 0.9965 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9984 - dense_2_accuracy_6: 0.9930 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 0.9977 - dense_2_accuracy_9: 0.9945 - dense_2_loss: 0.0199 - loss: 0.0916\n",
      "Epoch 14/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9993 - dense_2_accuracy_3: 0.9969 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9981 - dense_2_accuracy_6: 0.9947 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 0.9988 - dense_2_accuracy_9: 0.9984 - dense_2_loss: 0.0118 - loss: 0.0683\n",
      "Epoch 15/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9997 - dense_2_accuracy_3: 0.9960 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9994 - dense_2_accuracy_6: 0.9967 - dense_2_accuracy_7: 0.9999 - dense_2_accuracy_8: 0.9964 - dense_2_accuracy_9: 0.9968 - dense_2_loss: 0.0147 - loss: 0.0698\n",
      "Epoch 16/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9992 - dense_2_accuracy_3: 0.9965 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9984 - dense_2_accuracy_6: 0.9974 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 0.9974 - dense_2_accuracy_9: 0.9938 - dense_2_loss: 0.0209 - loss: 0.0849\n",
      "Epoch 17/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 0.9993 - dense_2_accuracy_1: 0.9989 - dense_2_accuracy_2: 0.9932 - dense_2_accuracy_3: 0.9921 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9966 - dense_2_accuracy_6: 0.9853 - dense_2_accuracy_7: 0.9997 - dense_2_accuracy_8: 0.9858 - dense_2_accuracy_9: 0.9833 - dense_2_loss: 0.0553 - loss: 0.2309\n",
      "Epoch 18/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9999 - dense_2_accuracy_3: 0.9979 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9999 - dense_2_accuracy_6: 0.9974 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 0.9991 - dense_2_accuracy_9: 0.9986 - dense_2_loss: 0.0105 - loss: 0.0476\n",
      "Epoch 19/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9996 - dense_2_accuracy_3: 0.9971 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 0.9988 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 0.9999 - dense_2_accuracy_9: 0.9995 - dense_2_loss: 0.0056 - loss: 0.0349\n",
      "Epoch 20/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9997 - dense_2_accuracy_3: 0.9987 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9999 - dense_2_accuracy_6: 0.9982 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 0.9999 - dense_2_loss: 0.0052 - loss: 0.0286\n",
      "Epoch 21/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9997 - dense_2_accuracy_3: 0.9983 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9999 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 0.9998 - dense_2_accuracy_9: 0.9998 - dense_2_loss: 0.0038 - loss: 0.0203\n",
      "Epoch 22/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9998 - dense_2_accuracy_3: 0.9985 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 0.0025 - loss: 0.0157\n",
      "Epoch 23/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9999 - dense_2_accuracy_3: 0.9984 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 0.0025 - loss: 0.0139\n",
      "Epoch 24/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9993 - dense_2_accuracy_3: 0.9964 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 0.9996 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 0.0028 - loss: 0.0251\n",
      "Epoch 25/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 1.0000 - dense_2_accuracy_3: 0.9985 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 0.0016 - loss: 0.0102\n",
      "Epoch 26/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9995 - dense_2_accuracy_3: 0.9983 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 0.0016 - loss: 0.0158\n",
      "Epoch 27/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 1.0000 - dense_2_accuracy_3: 0.9987 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 0.0013 - loss: 0.0097\n",
      "Epoch 28/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 1.0000 - dense_2_accuracy_3: 0.9988 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 0.0012 - loss: 0.0082\n",
      "Epoch 29/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 0.9999 - dense_2_accuracy_1: 0.9999 - dense_2_accuracy_2: 0.9982 - dense_2_accuracy_3: 0.9946 - dense_2_accuracy_4: 0.9999 - dense_2_accuracy_5: 0.9930 - dense_2_accuracy_6: 0.9851 - dense_2_accuracy_7: 0.9996 - dense_2_accuracy_8: 0.9677 - dense_2_accuracy_9: 0.9812 - dense_2_loss: 0.0567 - loss: 0.2884\n",
      "Epoch 30/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9997 - dense_2_accuracy_3: 0.9968 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9990 - dense_2_accuracy_6: 0.9915 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 0.9983 - dense_2_accuracy_9: 0.9956 - dense_2_loss: 0.0166 - loss: 0.0867\n",
      "Epoch 31/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9997 - dense_2_accuracy_3: 0.9979 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9999 - dense_2_accuracy_6: 0.9984 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 0.9987 - dense_2_loss: 0.0055 - loss: 0.0274\n",
      "Epoch 32/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9995 - dense_2_accuracy_3: 0.9976 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 0.9998 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 0.9998 - dense_2_loss: 0.0028 - loss: 0.0197\n",
      "Epoch 33/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9999 - dense_2_accuracy_3: 0.9987 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 0.0019 - loss: 0.0125\n",
      "Epoch 34/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 0.9999 - dense_2_accuracy_1: 0.9996 - dense_2_accuracy_2: 0.9991 - dense_2_accuracy_3: 0.9957 - dense_2_accuracy_4: 0.9999 - dense_2_accuracy_5: 0.9998 - dense_2_accuracy_6: 0.9983 - dense_2_accuracy_7: 0.9999 - dense_2_accuracy_8: 0.9994 - dense_2_accuracy_9: 0.9976 - dense_2_loss: 0.0088 - loss: 0.0420\n",
      "Epoch 35/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9997 - dense_2_accuracy_3: 0.9980 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 0.9988 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 0.9968 - dense_2_loss: 0.0098 - loss: 0.0326\n",
      "Epoch 36/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9999 - dense_2_accuracy_3: 0.9985 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9999 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 0.9992 - dense_2_loss: 0.0035 - loss: 0.0169\n",
      "Epoch 37/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9998 - dense_2_accuracy_3: 0.9989 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 9.9856e-04 - loss: 0.0085\n",
      "Epoch 38/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9998 - dense_2_accuracy_3: 0.9991 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 8.8853e-04 - loss: 0.0080\n",
      "Epoch 39/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9999 - dense_2_accuracy_3: 0.9992 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 7.6916e-04 - loss: 0.0062\n",
      "Epoch 40/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9998 - dense_2_accuracy_3: 0.9994 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 6.8186e-04 - loss: 0.0065\n",
      "Epoch 41/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9999 - dense_2_accuracy_3: 0.9982 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 7.0010e-04 - loss: 0.0083\n",
      "Epoch 42/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9998 - dense_2_accuracy_3: 0.9986 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 7.2975e-04 - loss: 0.0078\n",
      "Epoch 43/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 1.0000 - dense_2_accuracy_3: 0.9983 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 6.3848e-04 - loss: 0.0075\n",
      "Epoch 44/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 1.0000 - dense_2_accuracy_3: 0.9994 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 5.2690e-04 - loss: 0.0046\n",
      "Epoch 45/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9998 - dense_2_accuracy_3: 0.9991 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 7.7217e-04 - loss: 0.0082\n",
      "Epoch 46/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9998 - dense_2_accuracy_3: 0.9992 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 5.4612e-04 - loss: 0.0049\n",
      "Epoch 47/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9998 - dense_2_accuracy_3: 0.9994 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 5.5141e-04 - loss: 0.0050\n",
      "Epoch 48/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9998 - dense_2_accuracy_3: 0.9995 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 4.6720e-04 - loss: 0.0038\n",
      "Epoch 49/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9994 - dense_2_accuracy_3: 0.9984 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9998 - dense_2_accuracy_6: 0.9982 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 0.9996 - dense_2_accuracy_9: 0.9990 - dense_2_loss: 0.0048 - loss: 0.0226\n",
      "Epoch 50/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 0.9992 - dense_2_accuracy_2: 0.9993 - dense_2_accuracy_3: 0.9932 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9975 - dense_2_accuracy_6: 0.9905 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 0.9976 - dense_2_accuracy_9: 0.9930 - dense_2_loss: 0.0262 - loss: 0.1134\n",
      "Epoch 51/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9998 - dense_2_accuracy_3: 0.9977 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9996 - dense_2_accuracy_6: 0.9974 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 0.9995 - dense_2_accuracy_9: 0.9979 - dense_2_loss: 0.0056 - loss: 0.0314\n",
      "Epoch 52/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9997 - dense_2_accuracy_3: 0.9990 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 8.4541e-04 - loss: 0.0098\n",
      "Epoch 53/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9999 - dense_2_accuracy_3: 0.9989 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 3.1110e-04 - loss: 0.0061\n",
      "Epoch 54/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9994 - dense_2_accuracy_3: 0.9980 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 4.5239e-04 - loss: 0.0094\n",
      "Epoch 55/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9998 - dense_2_accuracy_3: 0.9989 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 2.9835e-04 - loss: 0.0053\n",
      "Epoch 56/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9999 - dense_2_accuracy_3: 0.9988 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 2.6087e-04 - loss: 0.0043\n",
      "Epoch 57/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9997 - dense_2_accuracy_3: 0.9976 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 3.3915e-04 - loss: 0.0075\n",
      "Epoch 58/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 1.0000 - dense_2_accuracy_3: 0.9970 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 4.1677e-04 - loss: 0.0155\n",
      "Epoch 59/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9999 - dense_2_accuracy_3: 0.9993 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 3.1175e-04 - loss: 0.0038\n",
      "Epoch 60/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9999 - dense_2_accuracy_3: 0.9992 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 3.1948e-04 - loss: 0.0045\n",
      "Epoch 61/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 0.9999 - dense_2_accuracy_2: 0.9979 - dense_2_accuracy_3: 0.9961 - dense_2_accuracy_4: 0.9999 - dense_2_accuracy_5: 0.9991 - dense_2_accuracy_6: 0.9942 - dense_2_accuracy_7: 0.9998 - dense_2_accuracy_8: 0.9929 - dense_2_accuracy_9: 0.9928 - dense_2_loss: 0.0246 - loss: 0.0918\n",
      "Epoch 62/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9998 - dense_2_accuracy_3: 0.9965 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9999 - dense_2_accuracy_6: 0.9992 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 0.9999 - dense_2_accuracy_9: 0.9994 - dense_2_loss: 0.0039 - loss: 0.0307\n",
      "Epoch 63/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9999 - dense_2_accuracy_3: 0.9966 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 0.9999 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 0.9999 - dense_2_accuracy_9: 0.9990 - dense_2_loss: 0.0036 - loss: 0.0194\n",
      "Epoch 64/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9999 - dense_2_accuracy_3: 0.9987 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 5.0706e-04 - loss: 0.0076\n",
      "Epoch 65/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9996 - dense_2_accuracy_3: 0.9992 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 3.0480e-04 - loss: 0.0044\n",
      "Epoch 66/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9997 - dense_2_accuracy_3: 0.9986 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 2.4239e-04 - loss: 0.0059\n",
      "Epoch 67/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9999 - dense_2_accuracy_3: 0.9995 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 1.9753e-04 - loss: 0.0033\n",
      "Epoch 68/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9999 - dense_2_accuracy_3: 0.9993 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 2.0122e-04 - loss: 0.0039\n",
      "Epoch 69/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9996 - dense_2_accuracy_3: 0.9987 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 1.8257e-04 - loss: 0.0046\n",
      "Epoch 70/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9998 - dense_2_accuracy_3: 0.9996 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 1.6589e-04 - loss: 0.0027\n",
      "Epoch 71/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9999 - dense_2_accuracy_3: 0.9989 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 1.6858e-04 - loss: 0.0034\n",
      "Epoch 72/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9998 - dense_2_accuracy_3: 0.9996 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 1.5179e-04 - loss: 0.0022\n",
      "Epoch 73/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9999 - dense_2_accuracy_3: 0.9996 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 1.7063e-04 - loss: 0.0027\n",
      "Epoch 74/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 1.0000 - dense_2_accuracy_3: 0.9989 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 1.6404e-04 - loss: 0.0032\n",
      "Epoch 75/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 1.0000 - dense_2_accuracy_3: 0.9993 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 1.5464e-04 - loss: 0.0039\n",
      "Epoch 76/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9996 - dense_2_accuracy_3: 0.9971 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 0.9998 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 4.6252e-04 - loss: 0.0088\n",
      "Epoch 77/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9999 - dense_2_accuracy_3: 0.9993 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 1.7667e-04 - loss: 0.0031\n",
      "Epoch 78/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 0.9999 - dense_2_accuracy_1: 0.9998 - dense_2_accuracy_2: 0.9981 - dense_2_accuracy_3: 0.9954 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9916 - dense_2_accuracy_6: 0.9927 - dense_2_accuracy_7: 0.9999 - dense_2_accuracy_8: 0.9942 - dense_2_accuracy_9: 0.9951 - dense_2_loss: 0.0171 - loss: 0.1243\n",
      "Epoch 79/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 0.9989 - dense_2_accuracy_1: 0.9996 - dense_2_accuracy_2: 0.9809 - dense_2_accuracy_3: 0.9741 - dense_2_accuracy_4: 0.9986 - dense_2_accuracy_5: 0.9954 - dense_2_accuracy_6: 0.9828 - dense_2_accuracy_7: 0.9983 - dense_2_accuracy_8: 0.9818 - dense_2_accuracy_9: 0.9773 - dense_2_loss: 0.0715 - loss: 0.3854\n",
      "Epoch 80/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 0.9992 - dense_2_accuracy_1: 0.9991 - dense_2_accuracy_2: 0.9977 - dense_2_accuracy_3: 0.9929 - dense_2_accuracy_4: 0.9983 - dense_2_accuracy_5: 0.9985 - dense_2_accuracy_6: 0.9967 - dense_2_accuracy_7: 0.9985 - dense_2_accuracy_8: 0.9919 - dense_2_accuracy_9: 0.9946 - dense_2_loss: 0.0241 - loss: 0.1477\n",
      "Epoch 81/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9998 - dense_2_accuracy_3: 0.9969 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 0.9999 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 0.9994 - dense_2_accuracy_9: 0.9998 - dense_2_loss: 0.0017 - loss: 0.0195\n",
      "Epoch 82/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9998 - dense_2_accuracy_3: 0.9976 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 0.9999 - dense_2_accuracy_6: 0.9999 - dense_2_accuracy_7: 0.9999 - dense_2_accuracy_8: 0.9997 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 7.3281e-04 - loss: 0.0133\n",
      "Epoch 83/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9997 - dense_2_accuracy_3: 0.9981 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 5.9393e-04 - loss: 0.0091\n",
      "Epoch 84/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9998 - dense_2_accuracy_3: 0.9983 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 3.9697e-04 - loss: 0.0064\n",
      "Epoch 85/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9999 - dense_2_accuracy_3: 0.9996 - dense_2_accuracy_4: 0.9999 - dense_2_accuracy_5: 0.9999 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 0.9999 - dense_2_accuracy_8: 0.9999 - dense_2_accuracy_9: 0.9999 - dense_2_loss: 6.2533e-04 - loss: 0.0054\n",
      "Epoch 86/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9996 - dense_2_accuracy_3: 0.9997 - dense_2_accuracy_4: 0.9999 - dense_2_accuracy_5: 0.9999 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 3.9728e-04 - loss: 0.0054\n",
      "Epoch 87/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9998 - dense_2_accuracy_3: 0.9994 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 4.3830e-04 - loss: 0.0048\n",
      "Epoch 88/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 1.0000 - dense_2_accuracy_3: 0.9994 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 2.9838e-04 - loss: 0.0037\n",
      "Epoch 89/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 1.0000 - dense_2_accuracy_3: 0.9997 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 4.1243e-04 - loss: 0.0032\n",
      "Epoch 90/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9999 - dense_2_accuracy_3: 0.9990 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 2.3832e-04 - loss: 0.0042\n",
      "Epoch 91/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 1.0000 - dense_2_accuracy_3: 0.9990 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 2.4243e-04 - loss: 0.0036\n",
      "Epoch 92/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9997 - dense_2_accuracy_3: 0.9993 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 2.0999e-04 - loss: 0.0030\n",
      "Epoch 93/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9996 - dense_2_accuracy_3: 0.9983 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 2.1194e-04 - loss: 0.0050\n",
      "Epoch 94/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9999 - dense_2_accuracy_3: 0.9983 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 2.3584e-04 - loss: 0.0052\n",
      "Epoch 95/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9998 - dense_2_accuracy_3: 0.9993 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 1.8322e-04 - loss: 0.0034\n",
      "Epoch 96/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 1.0000 - dense_2_accuracy_3: 0.9996 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 1.8868e-04 - loss: 0.0023\n",
      "Epoch 97/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9999 - dense_2_accuracy_3: 0.9990 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 1.9399e-04 - loss: 0.0043\n",
      "Epoch 98/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9999 - dense_2_accuracy_3: 0.9989 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 1.8790e-04 - loss: 0.0036\n",
      "Epoch 99/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9997 - dense_2_accuracy_3: 0.9988 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 2.2174e-04 - loss: 0.0047\n",
      "Epoch 100/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - dense_2_accuracy: 1.0000 - dense_2_accuracy_1: 1.0000 - dense_2_accuracy_2: 0.9998 - dense_2_accuracy_3: 0.9985 - dense_2_accuracy_4: 1.0000 - dense_2_accuracy_5: 1.0000 - dense_2_accuracy_6: 1.0000 - dense_2_accuracy_7: 1.0000 - dense_2_accuracy_8: 1.0000 - dense_2_accuracy_9: 1.0000 - dense_2_loss: 1.8849e-04 - loss: 0.0051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7a1611fa4140>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([Xoh, s0, c0], outputs, epochs=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd97fd07-0b34-4b88-a417-3b26aeb1cf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "source: 3 May 1979\n",
      "output: 1979-05-03 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "source: 5 April 09\n",
      "output: 2019-04-05 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "source: 21th of August 2016\n",
      "output: 2016-08-21 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "source: Tue 10 Jul 2007\n",
      "output: 2007-07-10 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "source: Saturday May 9 2018\n",
      "output: 2018-05-09 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_360824/2649609632.py:12: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  output = [inv_machine_vocab[int(i)] for i in prediction]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "source: March 3 2001\n",
      "output: 2001-03-03 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "source: March 3rd 2001\n",
      "output: 2001-03-03 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "source: 1 March 2001\n",
      "output: 2001-03-01 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\n",
    "s00 = np.zeros((1, n_s))\n",
    "c00 = np.zeros((1, n_s))\n",
    "for example in EXAMPLES:\n",
    "    source = string_to_int(example, Tx, human_vocab)\n",
    "    #print(source)\n",
    "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source))).swapaxes(0,1)\n",
    "    source = np.swapaxes(source, 0, 1)\n",
    "    source = np.expand_dims(source, axis=0)\n",
    "    prediction = model.predict([source, s00, c00])\n",
    "    prediction = np.argmax(prediction, axis = -1)\n",
    "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
    "    print(\"source:\", example)\n",
    "    print(\"output:\", ''.join(output),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ddaca7-8213-43b1-a20f-adbe1de18f36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
